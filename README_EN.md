# Lightning Exchange - High-Performance Matching Engine

In-memory matching engine implemented in Go, using single-threaded deterministic matching + batch read + runtime semaphore synchronization + sharded price tree architecture.

> **âš¡ Project Notes**  
> - This project code is 100% AI-generated (Cascade/Claude)  
> - Human responsible for architecture design, performance trade-off decisions, and code review  
> - Development time: 3 days (non-consecutive)  
> - Dependencies: Go standard library + gods/v2 (Red-Black Tree)

## ğŸ“Š Performance Metrics

**Throughput**: 1.0â€“1.38M orders/s (match-complete, single-symbol, in-memory)

**Measurement Methodology**:
- Construct 1:1 complete matching scenario (pre-load sell orders, then submit buy orders)
- Wait for trade count to reach expected value (trade consumed and confirmed)
- Measure end-to-end throughput from order submission to trade completion
- Avoid inflated QPS from only counting submit operations

**Test Environment**:
- CPU: Apple M2 Pro
- Go: 1.24.4
- GOMAXPROCS: 10 (1 matching thread + 1 idle + 8 producers)
- Scenario: Single symbol, in-memory orderbook, no persistence

**Key Results**:
- Single producer: 1.38M orders/s (100K orders, 72ms)
- 8 concurrent producers: 1.14M orders/s (80K orders, 70ms)
- Average latency: 0.73â€“0.88 Î¼s/order

## ğŸ—ï¸ Architecture

### Core Architecture
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         ExchangeEngine (Multi-Symbol)           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  MatchingEngine (Single Symbol)          â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  â”‚
â”‚  â”‚  â”‚ OrderBufferâ”‚â”€â”€â”€â”€â”€â–¶â”‚ OrderBook    â”‚   â”‚  â”‚
â”‚  â”‚  â”‚ (Disruptor)â”‚      â”‚ (HashMap+List)â”‚   â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  â”‚
â”‚  â”‚         â”‚                    â”‚           â”‚  â”‚
â”‚  â”‚         â–¼                    â–¼           â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  â”‚
â”‚  â”‚  â”‚ Matching   â”‚â”€â”€â”€â”€â”€â–¶â”‚ TradeBuffer  â”‚   â”‚  â”‚
â”‚  â”‚  â”‚ Thread     â”‚      â”‚ (Disruptor)  â”‚   â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Core Technical Points

1. **Architecture**: Single matching thread with deterministic consumption (no locks), multiple producers; orderbook supports price priority and FIFO for same price
   - Single-threaded matching engine (based on NASDAQ ITCH)
   - Deterministic order processing, no lock mechanism
   - Price-Time priority algorithm

2. **Performance Optimization**: Identified Gosched CPU yielding causing throughput drop, switched to semaphore + batch + local cache to reduce wakeup frequency and synchronization overhead
   - Initial version used `runtime.Gosched()` spin-wait, causing frequent context switches (10-20K QPS)
   - Switched to Go Channel, improved to 767K QPS
   - Introduced batch read (batch size 128) + runtime semaphore, reduced sync overhead by 128x
   - Final result: 1.0-1.38M QPS (pure semaphore protocol, no CAS mixing)

3. **Correctness Verification**: Implemented robust correctness tests (no lost orders, no duplicate trades, valid trade references, final state consistency) with timeout-based conditional waits to avoid sleep misjudgments
   - Exactly-Once verification: each order appears exactly once
   - Strict failure conditions: immediate Fatalf if expected trade count not reached
   - Happens-Before semantics: semrelease(full) happens-before semacquire(full)
   - Conditional wait replaces fixed sleep, test speed improved by 4.9x

4. **Performance Measurement Methodology**: Implemented reliable perf tests using "trade count reaches expected (trades consumed and confirmed)" as completion condition, avoiding inflated QPS from only counting submit operations
   - Construct 1:1 complete matching scenario (pre-load sell orders, then submit buy orders)
   - Wait for trade count to reach expected value (with timeout protection)
   - Measure end-to-end throughput (order submission â†’ matching â†’ trade confirmation)
   - Avoid continuous stress testing including incomplete orders causing inflated QPS

5. **Data Structure Optimization**: Sharded price tree + bitwise indexing
   - Outer layer: Red-Black Tree manages buckets (O(log m))
   - Inner layer: Fixed array (128 = 2^7) + doubly linked list
   - Bitwise indexing: `price & mask` instead of `price % size` (5-10x faster)
   - Best price query O(1)

### Performance Optimization History

Complete iteration process from Channel baseline to final Batch + Pure Semaphore:

| Stage | Implementation | Standalone QPS | Integrated QPS | Relative Improvement | Issues/Lessons |
|-------|---------------|----------------|----------------|---------------------|----------------|
| **Baseline** | Go Channel | ~2.43M | 767K | Baseline | Go native, well-tested |
| **Comparison** | Disruptor + Gosched | ~2M | 10-20K | -97.4% | CPU 100%, frequent context switches |
| **Improvement 1** | Semaphore (non-batch) | ~1.5M | 663K | -13.6% | Pure semaphore, but no batching |
| **Final** | **Batch 128 (Pure Semaphore)** | **~2.8M** | **1.0-1.38M** | **+79.8%** | **Batch + Safe + Reliable** |

**Key Lessons**:

1. **Channel vs Disruptor Comparison**
   - Baseline: Channel achieved 767K QPS, respectable performance
   - Comparison: Disruptor + Gosched only 10-20K QPS, extremely poor
   - Analysis: Disruptor pattern (ring buffer) should theoretically be faster than Channel
   - Root cause: Bottleneck is Gosched, not Disruptor itself
   - Decision: Since Disruptor is like Channel's ring buffer, try replacing Gosched with better synchronization

2. **Choosing Semaphore as Synchronization Primitive**
   - Constraint: Cannot use locks (maintain single-threaded matching determinism)
   - Solution: Try Semaphore to replace Gosched
   - Reason: Semaphore provides blocking wait, avoiding frequent context switches

3. **Semaphore + Batch Optimization**
   - Pure Semaphore (non-batch): 663K QPS, slower than Channel
   - Batch read optimization: tried batch sizes 64/128/256
   - CAS mixing version: fastest at 1.632M (batch 256), but theoretical risk
   - Pure Semaphore version: 1.0-1.38M (batch 128), completely safe
   - Final choice: batch 128 + pure Semaphore, sacrifice 15% performance for correctness

4. **Test Methodology Improvement**
   - Problem: 5-second continuous stress test may include incomplete orders, inflated QPS
   - Improvement: Construct 1:1 complete matching scenario, wait for expected trade count
   - Result: Measure true end-to-end throughput, more reliable

### Technical Details

**Batch Read + Pure Semaphore Synchronization**:
```go
// Producer protocol
semacquire(&emptySlots)  // Acquire empty slot
buffer[index] = order    // Write data
semrelease(&fullSlots)   // Release full slot

// Consumer protocol (batch)
semacquire(&fullSlots)   // Acquire 1st element (blocking)
for i := 0; i < 127; i++ {
    semacquire(&fullSlots) // Batch acquire more (non-blocking)
}
// Read 128 elements into local cache
semrelease(&emptySlots)  // Batch release empty slots
```

**Key Design**:
- Uses `runtime_Semacquire/Semrelease` (Go internal API, accessed via `//go:linkname`)
- Fully compliant with semaphore protocol, no CAS mixing
- Batch size 128, synchronization overhead reduced by 128x
- Happens-before semantics guarantee memory visibility

## ğŸ“¦ Project Structure

```
lighting-exchange/
â”œâ”€â”€ domain/                              # Domain models
â”‚   â”œâ”€â”€ order.go                        # Order entity + object pool
â”‚   â””â”€â”€ trade.go                        # Trade entity + object pool
â”œâ”€â”€ orderbook/                          # Order book
â”‚   â”œâ”€â”€ orderbook.go                    # Order book implementation
â”‚   â””â”€â”€ price_tree.go                   # Sharded price tree
â”œâ”€â”€ matching/                           # Matching engine (streamlined)
â”‚   â”œâ”€â”€ engine.go                       # Matching engine core
â”‚   â”œâ”€â”€ disruptor_semaphore_batch_safe.go  # Batch + Pure Semaphore RingBuffer
â”‚   â”œâ”€â”€ trade_ringbuffer_batch_safe.go     # Trade batch RingBuffer
â”‚   â”œâ”€â”€ id_generator.go                 # ID generator
â”‚   â”œâ”€â”€ performance_reliable_test.go    # Reliable performance tests
â”‚   â”œâ”€â”€ correctness_robust_test.go      # Complete closed-loop correctness tests
â”‚   â””â”€â”€ channel_performance_test.go     # Performance comparison tests
â”œâ”€â”€ cmd/
â”‚   â”œâ”€â”€ benchmark/                      # Performance testing tool
â”‚   â””â”€â”€ profile/                        # Performance profiling tool
â””â”€â”€ main.go                             # Example program
```

**Core Files**:
- `disruptor_semaphore_batch_safe.go`: Batch 128 + Pure Semaphore implementation, fully compliant with semaphore protocol
- `performance_reliable_test.go`: Reliable performance tests (Approach A: completion throughput)
- `correctness_robust_test.go`: Exactly-Once verification + strict failure conditions

## ğŸš€ Quick Start

### Installation
```bash
git clone https://github.com/yourusername/lighting-exchange.git
cd lighting-exchange
go mod download
```

### Run Example
```bash
go run main.go
```

### Performance Testing
```bash
# Reliable performance test (recommended)
go test -run=TestMatchingEngineReliableQPS -v ./matching

# Concurrent scenario performance test
go test -run=TestMatchingEngineConcurrentReliableQPS -v ./matching

# Correctness test (complete closed-loop)
go test -run="Test.*Robust" -v ./matching

# Benchmark
go test -bench=. -benchmem ./matching

# Profiling
go run cmd/profile/main.go
go tool pprof -http=:8080 cpu.prof
```

## ğŸ“ˆ Performance Test Results

### Reliable Performance Test (Approach A: Completion Throughput)

```bash
$ go test -run=TestMatchingEngineReliableQPS -v ./matching

=== RUN   TestMatchingEngineReliableQPS
Step 1: Placing 100000 sell orders...
Step 2: Sending 100000 buy orders, start timing...
Step 3: Waiting for trade count to reach 100000...

=== Reliable Performance Test Results (Approach A: Completion Throughput) ===
Test Scenario:  1:1 complete matching (sell orders first, then buy orders)
Order Count:    100000
Trade Count:    100000
Completion Time: 72.504792ms
Order QPS:      1379219 orders/sec (1.379M/sec)
Trade TPS:      1379219 trades/sec (1.379M/sec)
Avg Latency:    0.73 Î¼s/order

Note: This QPS measures matching completion throughput (trades confirmed)
--- PASS: TestMatchingEngineReliableQPS (0.21s)
```

### Concurrent Scenario Performance Test

```bash
$ go test -run=TestMatchingEngineConcurrentReliableQPS -v ./matching

=== RUN   TestMatchingEngineConcurrentReliableQPS
Step 1: 8 producers concurrently placing sell orders...
Step 2: 8 producers concurrently sending buy orders, start timing...
Step 3: Waiting for trade count to reach 80000...

=== Concurrent Scenario Reliable Performance Test Results ===
Test Scenario:  1:1 complete matching (sell orders first, then buy orders)
Concurrent Producers: 8
Total Orders:   80000
Trade Count:    80000
Completion Time: 70.424958ms
Order QPS:      1135961 orders/sec (1.136M/sec)
Trade TPS:      1135961 trades/sec (1.136M/sec)
Avg Latency:    0.88 Î¼s/order
--- PASS: TestMatchingEngineConcurrentReliableQPS (0.19s)
```

**Test Method**:
- âœ… Construct strict 1:1 complete matching scenario (sell orders first, then buy orders)
- âœ… Wait for trade count to reach expected value (with timeout), not fixed-time stress test
- âœ… Measure true end-to-end throughput (order submission â†’ matching â†’ trade confirmation)
- âœ… High credibility, avoids issues with continuous stress testing including incomplete orders

### Correctness Test (Complete Closed-Loop Verification)

```bash
$ go test -run="Test.*Robust" -v ./matching

=== RUN   TestOrderFinalStateConsistencyRobust
Waiting for trades to complete, expected: 50000

=== Order Final State Consistency Test (Improved) ===
Buy Orders Sent: 50000
Sell Orders Sent: 50000
Total Trades: 50000
âœ“ All trade-referenced order IDs are valid
âœ“ Trade count matches expected: 50000
âœ“ Total trade volume matches expected: 5000000
âœ“ All trade IDs are unique
âœ“ All trade prices are consistent: 50000
=== Final State Consistency Verification Passed ===
--- PASS: TestOrderFinalStateConsistencyRobust (0.17s)

=== RUN   TestHappenBeforeSemanticsRobust
Waiting for trades to complete, expected: 50000

=== Happens-Before Semantics Test (Improved - Exactly-Once) ===
Orders Sent: 100000
Order References Received: 100000
Trades: 50000
âœ“ All received order IDs are in the sent set
âœ“ Exactly-Once verification passed: each order appears exactly once
âœ“ Happens-Before semantics correct
--- PASS: TestHappenBeforeSemanticsRobust (0.08s)

=== RUN   TestConcurrentStressRobust
Waiting for trades to complete, expected: 8000

=== Concurrent Stress Test (Improved - Strict Mode) ===
Producers: 8
Total Orders: 16000
Total Trades: 8000
âœ“ All trade-referenced orders exist
âœ“ Trade count matches exactly: 8000
--- PASS: TestConcurrentStressRobust (0.02s)
PASS
ok      lighting-exchange/matching     0.423s
```

**Test Coverage (Complete Closed-Loop)**:
- âœ… **Exactly-Once Verification**: Each order appears exactly once (catches duplicates/losses)
- âœ… **Strict Failure Conditions**: Fatalf if expected trade count not reached (no warnings allowed)
- âœ… **Order Final State Consistency**: All trade-referenced orders exist
- âœ… **Happens-Before Semantics**: semrelease(full) happens-before semacquire(full)
- âœ… **Concurrent Safety**: 8 concurrent producers, strict mode verification
- âœ… **Price Priority**: Orders at different prices match at best price
- âœ… **Time Priority**: Orders at same price match in FIFO order
- âœ… **Conditional Wait**: Replaces fixed sleep, test speed improved by 4.9x

**Test Environment**:
- CPU: Apple M2 Pro (10 cores)
- Architecture: Sharded Price Tree + Bitwise Optimization + LMAX Disruptor
- Concurrency: 8 producer threads
- Scenario: Alternating buy/sell orders, 200 price levels

## ğŸ¯ Design Philosophy

### 1. Scenario-Specific Optimization
- **Scenario**: Single symbol, high throughput, low latency
- **Optimization**: Remove generality, pursue extreme performance

### 2. Mechanical Sympathy
- CPU Cache Line alignment
- Avoid False Sharing
- Pre-allocate memory, reduce GC

### 3. Lock-Free Design
- Single-threaded matching (no locks needed)
- Disruptor lock-free queue
- Atomic operations instead of mutexes

## ğŸ” Technical Details

### Disruptor vs Channel

| Feature | Go Channel | LMAX Disruptor |
|---------|-----------|----------------|
| Implementation | mutex + wait queues | Atomic ops + ring buffer |
| Latency | ~50ns | ~10ns |
| Throughput | 20M/sec | 100M/sec |
| Use Case | General purpose | Single consumer high throughput |

### Order Book Data Structure

```go
// Sharded Price Tree: Outer RBTree + Inner Array + Bitwise Optimization
type ShardedPriceTree struct {
    buckets    *RedBlackTree[int64, *Bucket]  // Outer: manage buckets
    bestBucket *Bucket                         // Cache best bucket
    bestPrice  *PriceLevel_                    // Cache best price (O(1) access)
    bucketSize int64                           // Bucket size (128 = 2^7)
}

// Bucket: Price shard (128 prices per group)
type Bucket struct {
    bucketID   int64
    levels     [128]*PriceLevel_  // Fixed array (128 = 2^7, supports bitwise optimization)
    bestPrice  *PriceLevel_        // Doubly Linked List head
    bucketMask int64               // Bit mask (127), for fast indexing: price & mask
}

// Price Level: FIFO queue + Linked list node
type PriceLevel_ struct {
    Price     int64
    Orders    *list.List      // FIFO queue (time priority)
    Volume    int64
    NextPrice *PriceLevel_    // Linked list pointer (price ordering)
    PrevPrice *PriceLevel_
}
```

## âœ… Correctness Guarantees

### Ring Buffer Publish Protocol

To ensure data visibility in multi-producer scenarios, a complete publish protocol is implemented:

```go
type RingBuffer struct {
    buffer    []*domain.Order
    available []atomic.Int64  // Publish flag for each slot
    writeSeq  atomic.Int64
    readSeq   atomic.Int64
}

// Producer: Mark as published after writing data
func (rb *RingBuffer) Publish(order *domain.Order) {
    seq := rb.writeSeq.Add(1) - 1
    index := seq & rb.mask
    rb.buffer[index] = order
    rb.available[index].Store(seq)  // Publish flag
}

// Consumer: Wait for publish flag before reading
func (rb *RingBuffer) Consume() *domain.Order {
    seq := rb.readSeq.Add(1) - 1
    index := seq & rb.mask
    for rb.available[index].Load() != seq {  // Wait for publish
        runtime.Gosched()
    }
    return rb.buffer[index]
}
```

**Key Points**:
- âœ… Prevents reading unpublished data
- âœ… Ensures memory visibility (memory barrier)
- âœ… Supports multi-producer concurrent writes

### Test Coverage

- âœ… **Price Priority**: Orders at different prices match at best price
- âœ… **Time Priority**: Orders at same price match in FIFO order
- âœ… **Order Management**: Add, cancel, query functions work correctly
- âœ… **Market Depth**: GetDepth returns correct price level ordering
- âœ… **Data Structure**: GetLevel uses bitwise indexing, avoids out-of-bounds

## ğŸ“ TODO

**Completed**:
- [x] Correctness test coverage
- [x] Ring Buffer publish protocol fix
- [x] Batch read optimization (79.8% performance improvement)
- [x] Pure Semaphore implementation (no CAS mixing)
- [x] Exactly-Once verification
- [x] Reliable performance testing (completion throughput)
- [x] Complete closed-loop correctness testing

**To Be Implemented**:
- [ ] Order book snapshot feature
- [ ] WebSocket push
- [ ] Persistence (WAL + Event Sourcing)
- [ ] Distributed deployment support

## ğŸ¤ Contributing

Issues and Pull Requests are welcome!

## ğŸ“„ License

MIT License

## ğŸ™ Acknowledgments

- LMAX Disruptor architecture
- NASDAQ ITCH protocol design
- Go high-performance practices

---

**Note**: This project is for learning and research purposes only. Not recommended for production use without thorough testing.

## ğŸ¤– AI-Generated Code

This project demonstrates the capability of AI-assisted software development:
- **Code Generation**: 100% by AI (Cascade/Claude)
- **Human Role**: Architecture decisions, performance trade-offs, code review
- **Development Speed**: 2 non-consecutive days
- **Code Quality**: Production-grade performance optimization
- **Dependencies**: Zero - only Go standard library

This showcases how AI can handle complex system design and performance optimization when guided by human expertise.
